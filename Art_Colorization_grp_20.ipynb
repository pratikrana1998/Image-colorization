{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "image_folder_url = '/content/drive/MyDrive/input/painting'"
      ],
      "metadata": {
        "id": "PHvY9S5N4VUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "XNkw8nWXxoJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tqdm import tqdm\n",
        "from itertools import chain\n",
        "import skimage\n",
        "from PIL import Image\n",
        "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.util import crop\n",
        "from skimage.morphology import label\n",
        "from skimage.color import rgb2gray, gray2rgb, rgb2lab, lab2rgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
        "from keras.models import Model, load_model,Sequential\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Input, Dense, UpSampling2D, RepeatVector, Reshape\n",
        "from keras.layers.core import Dropout, Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "import datetime\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
        "seed = 42\n",
        "random.seed = seed\n",
        "np.random.seed = seed"
      ],
      "metadata": {
        "id": "ZQfucUG24t1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "IMG_CHANNELS = 3\n",
        "INPUT_SHAPE=(IMG_HEIGHT, IMG_WIDTH, 1)\n",
        "TRAIN_PATH = image_folder_url\n",
        "\n",
        "train_ids = next(os.walk(TRAIN_PATH))[2]\n",
        "print(train_ids)"
      ],
      "metadata": {
        "id": "JOIEz6yh5H1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X_train = np.zeros((len(train_ids)-86, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
        "missing_count = 0\n",
        "print('Getting train images ... ')\n",
        "sys.stdout.flush()\n",
        "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
        "    path = TRAIN_PATH + '/' + id_+''\n",
        "    try:\n",
        "        img = imread(path)\n",
        "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
        "        X_train[n-missing_count] = img\n",
        "    except:\n",
        "#         print(\" Problem with: \"+path)\n",
        "        missing_count += 1\n",
        "\n",
        "X_train = X_train.astype('float32') / 255.\n",
        "print(\"Total missing: \"+ str(missing_count))"
      ],
      "metadata": {
        "id": "2Od_YqiU5b5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(X_train[5])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mY4lJapn5fi8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = train_test_split(X_train, test_size=20, random_state=seed)"
      ],
      "metadata": {
        "id": "jNmIXHQO5i80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inception = InceptionResNetV2(weights=None, include_top=True)\n",
        "inception.load_weights('/content/drive/MyDrive/input/inception-resnet-v2-weights/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels.h5')\n",
        "# inception.graph = tf.compat.v1.get_default_graph()"
      ],
      "metadata": {
        "id": "by0SfdXR5mO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Colorize():\n",
        "    embed_input = Input(shape=(1000,))\n",
        "    \n",
        "    #Encoder\n",
        "    encoder_input = Input(shape=(256, 256, 1,))\n",
        "    encoder_output = Conv2D(128, (3,3), activation='relu', padding='same',strides=1)(encoder_input)\n",
        "    encoder_output = MaxPooling2D((2, 2), padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(128, (4,4), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(128, (3,3), activation='relu', padding='same',strides=1)(encoder_output)\n",
        "    encoder_output = MaxPooling2D((2, 2), padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (4,4), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same',strides=1)(encoder_output)\n",
        "    encoder_output = MaxPooling2D((2, 2), padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (4,4), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    encoder_output = Conv2D(256, (3,3), activation='relu', padding='same')(encoder_output)\n",
        "    \n",
        "    #Fusion\n",
        "    fusion_output = RepeatVector(32 * 32)(embed_input) \n",
        "    fusion_output = Reshape(([32, 32, 1000]))(fusion_output)\n",
        "    fusion_output = concatenate([encoder_output, fusion_output], axis=3) \n",
        "    fusion_output = Conv2D(256, (1, 1), activation='relu', padding='same')(fusion_output)\n",
        "    \n",
        "    #Decoder\n",
        "    decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(fusion_output)\n",
        "    decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "    decoder_output = Conv2D(128, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "    decoder_output = Conv2D(64, (4,4), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = Conv2D(64, (3,3), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = Conv2D(32, (2,2), activation='relu', padding='same')(decoder_output)\n",
        "    decoder_output = Conv2D(2, (3, 3), activation='tanh', padding='same')(decoder_output)\n",
        "    decoder_output = UpSampling2D((2, 2))(decoder_output)\n",
        "    return Model(inputs=[encoder_input, embed_input], outputs=decoder_output)\n",
        "\n",
        "model = Colorize()\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "SMdnXxC95xOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Image transformer\n",
        "datagen = ImageDataGenerator(\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        rotation_range=20,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "#Create embedding\n",
        "def create_inception_embedding(grayscaled_rgb):\n",
        "    def resize_gray(x):\n",
        "        return resize(x, (299, 299, 3), mode='constant')\n",
        "    grayscaled_rgb_resized = np.array([resize_gray(x) for x in grayscaled_rgb])\n",
        "    grayscaled_rgb_resized = preprocess_input(grayscaled_rgb_resized)\n",
        "    embed = inception.predict(grayscaled_rgb_resized)\n",
        "    return embed\n",
        "\n",
        "#Generate training data\n",
        "def image_a_b_gen(dataset=X_train, batch_size = 20):\n",
        "    for batch in datagen.flow(dataset, batch_size=batch_size):\n",
        "        X_batch = rgb2gray(batch)\n",
        "        grayscaled_rgb = gray2rgb(X_batch)\n",
        "        lab_batch = rgb2lab(batch)\n",
        "        X_batch = lab_batch[:,:,:,0]\n",
        "        X_batch = X_batch.reshape(X_batch.shape+(1,))\n",
        "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
        "        yield [X_batch, create_inception_embedding(grayscaled_rgb)], Y_batch\n",
        "        "
      ],
      "metadata": {
        "id": "XIDfmoiY6zqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a learning rate annealer\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='loss', \n",
        "                                            patience=3, \n",
        "                                            verbose=1, \n",
        "                                            factor=0.5,\n",
        "                                            min_lr=0.00001)\n",
        "filepath = \"content/Art_Colorization_Model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath,\n",
        "                             save_best_only=True,\n",
        "                             monitor='loss',\n",
        "                             mode='min')\n",
        "\n",
        "model_callbacks = [learning_rate_reduction,checkpoint]"
      ],
      "metadata": {
        "id": "YRTpQGkG7hu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "BATCH_SIZE = 20\n",
        "history = model.fit(image_a_b_gen(X_train,BATCH_SIZE),\n",
        "            epochs=30,\n",
        "            verbose=1,\n",
        "            steps_per_epoch=X_train.shape[0]/BATCH_SIZE,\n",
        "             callbacks=model_callbacks)"
      ],
      "metadata": {
        "id": "rztqA4oD7pMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(filepath)\n",
        "model.save_weights(\"Art_Colorization_Weights.h5\")\n"
      ],
      "metadata": {
        "id": "FHdtJQNb9cWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = history.history['loss']\n",
        "#loss_val = history.history['val_loss']\n",
        "epochs = range(1,31)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "#plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3wVnnwsDRlNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = X_test\n",
        "color_me = gray2rgb(rgb2gray(sample))\n",
        "color_me_embed = create_inception_embedding(color_me)\n",
        "color_me = rgb2lab(color_me)[:,:,:,0]\n",
        "color_me = color_me.reshape(color_me.shape+(1,))\n",
        "\n",
        "output = model.predict([color_me, color_me_embed])\n",
        "output = output * 128\n",
        "\n",
        "decoded_imgs = np.zeros((len(output),256, 256, 3))\n",
        "\n",
        "for i in range(len(output)):\n",
        "    cur = np.zeros((256, 256, 3))\n",
        "    cur[:,:,0] = color_me[i][:,:,0]\n",
        "    cur[:,:,1:] = output[i]\n",
        "    decoded_imgs[i] = lab2rgb(cur)\n",
        "    cv2.imwrite(\"img_\"+str(i)+\".jpg\", lab2rgb(cur))"
      ],
      "metadata": {
        "id": "uQb0TaX89c2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 6))\n",
        "for i in range(10):\n",
        "    # grayscale\n",
        "    plt.subplot(3, 10, i + 1)\n",
        "    plt.imshow(rgb2gray(X_test)[i].reshape(256, 256))\n",
        "    plt.gray()\n",
        "    plt.axis('off')\n",
        " \n",
        "    # recolorization\n",
        "    plt.subplot(3, 10, i + 1 +10)\n",
        "    plt.imshow(decoded_imgs[i].reshape(256, 256,3))\n",
        "    plt.axis('off')\n",
        "    \n",
        "    # original\n",
        "    plt.subplot(3, 10, i + 1 + 20)\n",
        "    plt.imshow(X_test[i].reshape(256, 256,3))\n",
        "    plt.axis('off')\n",
        " \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TyIPcJEI9gw8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}